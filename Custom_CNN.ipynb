{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "data_dir = r\"...\\Train\"\n",
    "test_data_dir = r'...\\Test'\n",
    "classes = ('covid', 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_transforms_train = transforms.Compose([\n",
    "    transforms.Resize(160),\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=180),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_transforms_val_test = transforms.Compose([\n",
    "    transforms.Resize(160),\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(data_dir, transform=data_transforms_train)\n",
    "val_test_dataset = ImageFolder(test_data_dir, transform=data_transforms_val_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "val_size = 50\n",
    "train_size = len(train_dataset) - val_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "test_loader = DataLoader(val_test_dataset, batch_size=batch_size, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(16, 12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path=\"./cust_cnn.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    accuracy, total = 0.0, 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # plot_confusion_matrix(cm, target_names=classes, normalize=False)\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        save_model(model)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, val_loader, optimizer, loss_fn, num_epochs=20):\n",
    "    best_accuracy = 0.0\n",
    "    model.to(device)\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
    "        val_accuracy, _, _, _ = evaluate(val_loader, model, device)\n",
    "\n",
    "        early_stopping(avg_train_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=9)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f\"{cm[i, j]:.4f}\" if normalize else f\"{cm[i, j]:,}\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=18)\n",
    "    plt.xlabel('Predicted label', fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        pretrained_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        for param in pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.conv1 = pretrained_model.conv1\n",
    "        self.bn1 = pretrained_model.bn1\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = pretrained_model.maxpool\n",
    "        self.layer1 = pretrained_model.layer1\n",
    "        self.layer2 = pretrained_model.layer2\n",
    "        self.custom_conv1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.custom_bn1 = nn.BatchNorm2d(256)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 37 * 37, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        x = self.custom_conv1(x)\n",
    "        x = self.custom_bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "\n",
    "\n",
    "    use_custom_net = True\n",
    "\n",
    "    if use_custom_net:\n",
    "        model = Net()\n",
    "        optimizer = optim.Adam([\n",
    "    {'params': model.conv1.parameters(), 'lr': 0.0001},\n",
    "    {'params': model.layer1.parameters(), 'lr': 0.0001},\n",
    "    {'params': model.layer2.parameters(), 'lr': 0.0001},\n",
    "    {'params': model.custom_conv1.parameters(), 'lr': 0.001},\n",
    "    {'params': model.fc1.parameters(), 'lr': 0.001},\n",
    "    {'params': model.fc2.parameters(), 'lr': 0.001}\n",
    "])\n",
    "\n",
    "    else:\n",
    "        \n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "        optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    train(model, device, train_loader, val_loader, optimizer, loss_fn)\n",
    "    print('Finished Training')\n",
    "    train_status = True\n",
    "    if train_status:\n",
    "        model.load_state_dict(torch.load(\"cust_cnn.pth\"))\n",
    "        model.to(device)\n",
    "        evaluate(test_loader, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
