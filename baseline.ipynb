{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import itertools\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "data_dir = r\"...\\Train\"\n",
    "test_data_dir = r'...\\Test'\n",
    "classes = ('covid', 'normal')\n",
    "def balance_dataset(base_dir, classes):\n",
    "\n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(base_dir, cls)\n",
    "        images = os.listdir(class_dir)\n",
    "        other_class = classes[1] if cls == classes[0] else classes[0]\n",
    "        other_class_dir = os.path.join(base_dir, other_class)\n",
    "        other_images = os.listdir(other_class_dir)\n",
    "        min_images = min(len(images), len(other_images))\n",
    "        if len(images) > min_images:\n",
    "            images_to_remove = random.sample(images, len(images) - min_images)\n",
    "            for img in images_to_remove:\n",
    "                os.remove(os.path.join(class_dir, img))\n",
    "        elif len(images) < min_images:\n",
    "            images_to_add = random.choices(images, k=min_images - len(images))\n",
    "            for img in images_to_add:\n",
    "                original_path = os.path.join(class_dir, img)\n",
    "                new_image_name = f\"copy_{img}\"\n",
    "                new_path = os.path.join(class_dir, new_image_name)\n",
    "                copyfile(original_path, new_path)\n",
    "\n",
    "balance_dataset(data_dir, classes)\n",
    "balance_dataset(test_data_dir, classes)\n",
    "\n",
    "print(\"Datasets balanced successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_transforms_train = transforms.Compose([\n",
    "    transforms.Resize(160),\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=180),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "data_transforms_val_test = transforms.Compose([\n",
    "    transforms.Resize(160),\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(data_dir, transform=data_transforms_train)\n",
    "val_test_dataset = ImageFolder(test_data_dir, transform=data_transforms_val_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "val_size = 50\n",
    "train_size = len(train_dataset) - val_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "test_loader = DataLoader(val_test_dataset, batch_size=batch_size, num_workers=2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(16, 12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model, path=\"./resnet18.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, device):\n",
    "    model.eval()\n",
    "    accuracy, total = 0.0, 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # plot_confusion_matrix(cm, target_names=classes, normalize=False)\n",
    "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        save_model(model)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, val_loader, optimizer, loss_fn, num_epochs=20):\n",
    "    best_accuracy = 0.0\n",
    "    model.to(device)\n",
    "    early_stopping = EarlyStopping(patience=1, verbose=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
    "        val_accuracy, _, _, _ = evaluate(val_loader, model, device)\n",
    "\n",
    "        early_stopping(avg_train_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f\"{cm[i, j]:.4f}\" if normalize else f\"{cm[i, j]:,}\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=18)\n",
    "    plt.xlabel('Predicted label', fontsize=18)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "    # Freeze all layers except the final fully connected layer\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Replace the final layer for your specific classification task\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(classes))\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "    train(model, device, train_loader, val_loader, optimizer, loss_fn)\n",
    "    print('Finished Training')\n",
    "    train_status = True\n",
    "    if train_status:\n",
    "        model.load_state_dict(torch.load(\"resnet18.pth\"))\n",
    "        model.to(device)\n",
    "        evaluate(test_loader, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchviz import make_dot\n",
    "import torchviz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  \n",
    "\n",
    "\n",
    "model_path = r'...\\Covid19\\Code\\resnet18.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "model.load_state_dict(checkpoint, strict=False)  \n",
    "model.eval()  \n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = r'...\\Covid19\\Code\\resnet18.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "test_data_path = r'...\\Test'\n",
    "test_data = datasets.ImageFolder(root=test_data_path, transform=test_transform)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        probabilities = nn.Softmax(dim=1)(outputs)  \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_probs.extend(probabilities[:, 1].numpy())  \n",
    "\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Covid'], yticklabels=['Normal', 'Covid'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(all_labels, all_preds, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) ')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--') \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f'AUC Score: {roc_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
